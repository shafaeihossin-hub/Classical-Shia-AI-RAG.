import os
from bs4 import BeautifulSoup # Ø§ÛŒÙ† Ú©ØªØ§Ø¨Ø®ÙˆÙ†Ù‡ Ø±Ùˆ Ø¨Ø§ÛŒØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒ: pip install beautifulsoup4
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct
from sentence_transformers import SentenceTransformer

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡
encoder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
client = QdrantClient(url="http://localhost:6333")
COLLECTION_NAME = "shia_ai_corpus"

def clean_html(html_content):
    """Ø§ÛŒÙ† Ù‡Ù…ÙˆÙ† Ú¯Ø§Ù… Ø§ÙˆÙ„Ù‡: ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† Ú©Ø¯Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÙ‡"""
    soup = BeautifulSoup(html_content, "html.parser")
    # Ø­Ø°Ù Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ Ùˆ Ø§Ø³ØªØ§ÛŒÙ„â€ŒÙ‡Ø§
    for script_or_style in soup(["script", "style"]):
        script_or_style.decompose()
    return soup.get_text(separator=' ', strip=True)

def ingest_folder(folder_path, source_type):
    if not os.path.exists(folder_path):
        print(f"âŒ Ù¾ÙˆØ´Ù‡ {folder_path} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!")
        return

    for filename in os.listdir(folder_path):
        if filename.endswith(".htm") or filename.endswith(".html"):
            path = os.path.join(folder_path, filename)
            with open(path, 'r', encoding='utf-8') as f:
                raw_content = f.read()
                text_content = clean_html(raw_content)
                # Ø§ÛŒÙ† Ø±Ùˆ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø§ÙˆÙ† Ø®Ø· chunks Ù‚Ø¨Ù„ÛŒ Ú©Ù†:
                overlap = 200 # Û²Û°Û° Ú©Ø§Ø±Ø§Ú©ØªØ± Ù‡Ù…Ù¾ÙˆØ´Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ù‡ÛŒÚ† Ø­Ø¯ÛŒØ«ÛŒ Ø§Ø² ÙˆØ³Ø· Ù‚Ø·Ø¹ Ù†Ø´Ù‡
                chunks = [text_content[i:i+1500] for i in range(0, len(text_content), 1500 - overlap)]
                
                points = []
                for i, chunk in enumerate(chunks):
                    if len(chunk) < 50: continue
                    vector = encoder.encode(chunk).tolist()
                    points.append(PointStruct(
                        id=hash(filename + str(i)) % (10**10),
                        vector=vector,
                        payload={"text": chunk, "source_type": source_type, "book": filename}
                    ))
                
                # --- Ø§ØµÙ„Ø§Ø­ Ø§ÛŒÙ†Ø¬Ø§Ø³Øª: Ø§Ø±Ø³Ø§Ù„ Ø¯Ø± Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Û±Û°Û° ØªØ§ÛŒÛŒ ---
                for j in range(0, len(points), 100):
                    batch = points[j:j+100]
                    client.upsert(collection_name=COLLECTION_NAME, points=batch)
                
                print(f"âœ… ÙØ§ÛŒÙ„ {filename} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªØ²Ø±ÛŒÙ‚ Ø´Ø¯.")

if __name__ == "__main__":
    # Ø§ÙˆÙ„ Ú©Ù„ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù‚Ø¨Ù„ÛŒ Ø±Ùˆ Ù¾Ø§Ú© Ú©Ù† Ú©Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø«ÛŒÙ Ø­Ø°Ù Ø¨Ø´Ù†
    client.recreate_collection(
        collection_name=COLLECTION_NAME,
        vectors_config={"size": 384, "distance": "Cosine"}
    )
    # Û². Ø­Ø§Ù„Ø§ Ù‡Ø± Ø³Ù‡ ØªØ§ Ù¾ÙˆØ´Ù‡ Ø±Ùˆ Ø¨Ø§ Ø¨Ø±Ú†Ø³Ø¨ Ù…Ø®ØµÙˆØµ Ø®ÙˆØ¯Ø´ÙˆÙ† ÙˆØ§Ø±Ø¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø¹Ù…Ù„ÛŒØ§Øª ØªØ²Ø±ÛŒÙ‚ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
    
    ingest_folder("shia_source", "Shia")
    ingest_folder("sunni_source", "Sunni")
    ingest_folder("common_source", "Common") # Ø§ÛŒÙ† Ù‡Ù…ÙˆÙ† Ù¾ÙˆØ´Ù‡ Ø³ÙˆÙ… Ú©Ù‡ ÛŒØ§Ø¯Ù…ÙˆÙ† Ø±ÙØªÙ‡ Ø¨ÙˆØ¯
    
    print("âœ¨ ØªÙ…ÙˆÙ… Ø´Ø¯! Ø­Ø§Ù„Ø§ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…Ø«Ù„ Ø¢ÛŒÙ†Ù‡ ØªÙ…ÛŒØ² Ùˆ Ù¾Ø± Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§ØªÙ‡.")